{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('adrecoffee', '20200120'), ('aemyeongyiheye', '20200120'), ('cafe.roha', '20200120')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from urllib.request import Request, urlopen\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# 해시태그 검색\n",
    "keyword = \"다랑쉬오름\"\n",
    "keyword = urllib.parse.quote(keyword)\n",
    "tag_search_url = \"https://www.instagram.com/explore/tags/{}/\".format(keyword)\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(tag_search_url)\n",
    "sleep(3)\n",
    "\n",
    "# 최근 사진 게시물 1건 클릭\n",
    "driver.find_element_by_xpath(\"//h2[text()='최근 사진']/following-sibling::div/div/div[1]/div[1]\").click()\n",
    "\n",
    "search_result_page_source = driver.page_source\n",
    "bsObj = BeautifulSoup(search_result_page_source, \"lxml\")\n",
    "\n",
    "post_info_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    sleep(1)\n",
    "    \n",
    "    # post 상세보기 화면\n",
    "    detail_page_source = driver.page_source\n",
    "    bsObj = BeautifulSoup(detail_page_source, \"lxml\")\n",
    "    post_id = bsObj.find(\"a\", {\"class\" : \"FPmhX notranslate nJAzx\"}).text # 작성자ID\n",
    "    post_date = bsObj.find_all(\"time\")[0].attrs[\"datetime\"][:10].replace(\"-\", \"\") # 게시일자\n",
    "    \n",
    "    post_info_list.append((post_id, post_date))\n",
    "\n",
    "    # 다음 post로 이동\n",
    "    try:\n",
    "        WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a.HBoOv.coreSpriteRightPaginationArrow')))\n",
    "        driver.find_element_by_css_selector('a.HBoOv.coreSpriteRightPaginationArrow').click()\n",
    "    except:\n",
    "        sleep(3)\n",
    "        print(\"Exception!!!!\")\n",
    "        driver.close()\n",
    "        break\n",
    "        \n",
    "print(post_info_list)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['다랑쉬오름']\n",
      "['다랑쉬오름', '월랑봉']\n",
      "['다랑쉬오름', '월랑봉', '제주여행']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을', '북힐링기행']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을', '북힐링기행', '꿈친구독서모임']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을', '북힐링기행', '꿈친구독서모임', '김미경캠퍼스']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을', '북힐링기행', '꿈친구독서모임', '김미경캠퍼스', '김미경유튜브대학장학생']\n",
      "['다랑쉬오름', '월랑봉', '제주여행', '오름오르기', '다랑쉬오름', '월랑봉', '아끈다랑쉬오름', '오름', '오름추천', '제주도', 'jeju', '그래동쪽이야', '예술인마을', '꿈이있는사람들', '관광마을', '생태동호인마을', '북힐링기행', '꿈친구독서모임', '김미경캠퍼스', '김미경유튜브대학장학생', '김미경유튜브대학']\n",
      "['0주', '0주', '14주']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "\n",
    "keyword = \"월랑봉\"\n",
    "url = \"https://www.instagram.com/explore/tags/{}/\".format(keyword)\n",
    "#url = \"https://www.instagram.com/p/B7hrSIklRP_/\"\n",
    "instagram_tags = []\n",
    "instagram_tag_dates = []\n",
    "driver = wd.Chrome(\"./chromedriver\")\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.find_element_by_css_selector('div.v1Nh3.kIKUG._bz0w').click()\n",
    "for i in range(3):\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        data = driver.find_element_by_css_selector('.C7I1f.X7jCj')  # C7I1f X7jCj\n",
    "        tag_raw = data.text\n",
    "        tags = re.findall('#[A-Za-z0-9가-힣]+', tag_raw)\n",
    "        tag = ''.join(tags).replace(\"#\", \" \")  # \"#\" 제거\n",
    "        tag_data = tag.split()\n",
    "\n",
    "        for tag_one in tag_data:\n",
    "            instagram_tags.append(tag_one)\n",
    "            print(instagram_tags)\n",
    "\n",
    "        date = driver.find_element_by_css_selector(\"time.FH9sR.Nzb55\").text  # 날짜 선택\n",
    "\n",
    "        if date.find('시간') != -1 or date.find('일') != -1 or date.find('분') != -1:\n",
    "            instagram_tag_dates.append('0주')\n",
    "        else:\n",
    "            instagram_tag_dates.append(date)\n",
    "            print(instagram_tag_dates)\n",
    "    except:\n",
    "        instagram_tags.append(\"error\")\n",
    "        instagram_tag_dates.append('error')\n",
    "    try:\n",
    "        WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a.HBoOv.coreSpriteRightPaginationArrow')))\n",
    "        driver.find_element_by_css_selector('a.HBoOv.coreSpriteRightPaginationArrow').click()\n",
    "    except:\n",
    "        driver.close()\n",
    "        # date = datum2.text\n",
    "    # print(date)\n",
    "    time.sleep(3)\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "from urllib.request import Request, urlopen\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# 해시태그 검색\n",
    "keyword = \"다랑쉬오름\"\n",
    "keyword = urllib.parse.quote(keyword)\n",
    "tag_search_url = \"https://www.instagram.com/explore/tags/{}/\".format(keyword)\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(tag_search_url)\n",
    "sleep(3)\n",
    "\n",
    "# 최근 사진 게시물 1건 클릭\n",
    "driver.find_element_by_xpath(\"//h2[text()='최근 사진']/following-sibling::div/div/div[1]/div[1]\").click()\n",
    "\n",
    "search_result_page_source = driver.page_source\n",
    "bsObj = BeautifulSoup(search_result_page_source, \"lxml\")\n",
    "\n",
    "post_info_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    sleep(1)\n",
    "    \n",
    "    # post 상세보기 화면\n",
    "    detail_page_source = driver.page_source\n",
    "    bsObj = BeautifulSoup(detail_page_source, \"lxml\")\n",
    "    post_id = bsObj.find(\"a\", {\"class\" : \"FPmhX notranslate nJAzx\"}).text # 작성자ID\n",
    "    post_date = bsObj.find_all(\"time\")[0].attrs[\"datetime\"][:10] # 게시일자\n",
    "    \n",
    "    post_info_list.append((post_id, post_date))\n",
    "\n",
    "    # 다음 post로 이동\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a.HBoOv.coreSpriteRightPaginationArrow')))\n",
    "        driver.find_element_by_css_selector('a.HBoOv.coreSpriteRightPaginationArrow').click()\n",
    "    except:\n",
    "        sleep(3)\n",
    "        print(\"Exception!!!!\")\n",
    "        #driver.close()\n",
    "        break\n",
    "        \n",
    "print(post_info_list)\n",
    "driver.close()\n",
    "\n",
    "return False\n",
    "\n",
    "pageString = driver.page_source\n",
    "bsObj = BeautifulSoup(pageString, \"lxml\")\n",
    "\n",
    "# 검색결과에서 최근게시물로 한 줄씩(3건의 게시글)\n",
    "children = bsObj.find(\"article\", {\"class\" : \"KC1QD\"}).findChildren(\"div\", recursive=False)\n",
    "recentObj = children[1] # 최근게시물 영역\n",
    "\n",
    "#for div_row in bsObj.find_all(name=\"div\",attrs={\"class\":\"Nnq7C weEfm\"}):\n",
    "for div_row in recentObj.find_all(name=\"div\",attrs={\"class\":\"Nnq7C weEfm\"}):\n",
    "    for a_onePostLink in div_row.select(\"a\"):\n",
    "        # 게시물 1건에 대한 링크에서 각 게시글 상세보기 주소 가져오기\n",
    "        a_onePostLinkAddress = a_onePostLink.attrs[\"href\"]\n",
    "        print(\"0-real:\", a_onePostLinkAddress)\n",
    "        reallink.append(a_onePostLinkAddress) \n",
    "\n",
    "csvtext = []\n",
    "\n",
    "print(reallink)\n",
    "\n",
    "reallinknum = len(reallink)\n",
    "print(\"총\"+str(reallinknum)+\"개의 데이터...\")\n",
    "\n",
    "try:\n",
    "    #for i in range(0,reallinknum):\n",
    "    for i in range(0,5):\n",
    "        csvtext.append([])\n",
    "        \n",
    "        request_url = \"https://www.instagram.com\" + reallink[i]\n",
    "        #print(\"reallink[i]:\", reallink[i])\n",
    "        print(\"request_url:\", request_url)\n",
    "        \n",
    "        req = Request(request_url, headers={\"User-Agent\" : \"Mozilla/5.0\"})\n",
    "\n",
    "        webpage = urlopen(req).read()\n",
    "        soup = BeautifulSoup(webpage, \"lxml\", from_encoding=\"utf-8\")\n",
    "        print(\"###################################\")\n",
    "        pprint.pprint(soup)\n",
    "        print(\"###################################\")\n",
    "        soup1 = soup.find(\"meta\", attrs={\"property\":\"og:description\"})\n",
    "        \n",
    "        reallink1 = soup1[\"content\"]\n",
    "        print(\"soup1[content]:\", reallink1)\n",
    "        reallink1 = reallink1[reallink1.find(\"@\")+1:reallink1.find(\")\")]\n",
    "        print(\"계정명:\", reallink1)\n",
    "        reallink1 = reallink1[:20]\n",
    "        if reallink1 == \"\":\n",
    "            reallink1 = \"Null\"\n",
    "            \n",
    "        #print(\"최종 reallink 1:\", reallink1)\n",
    "        csvtext[i].append(reallink1)\n",
    "        \n",
    "        for reallink2 in soup.find_all(\"meta\",attrs={\"property\":\"instapp:hashtags\"}): \n",
    "            reallink2 = reallink2[\"content\"]\n",
    "            csvtext[i].append(reallink2)\n",
    "            #print(\"reallink 2:\", reallink2)\n",
    " \n",
    "\n",
    "    print(str(i+1)+\"개의 데이터 받아오는 중.\")\n",
    "    print(csvtext)\n",
    "    data = pd.DataFrame(csvtext)\n",
    "    #data.to_csv('insta_success.csv', encoding='euc-kr')\n",
    "\n",
    "except:\n",
    "    print(\"오류발생\"+str(i+1)+\"개의 데이터를 저장합니다.\")\n",
    "    \n",
    "    data = pd.DataFrame(csvtext)\n",
    "    #data.to_csv('insta_error.csv', encoding='euc-kr')\n",
    "    \n",
    "print(\"저장성공\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
